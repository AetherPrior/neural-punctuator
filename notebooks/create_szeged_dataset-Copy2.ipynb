{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import AutoTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82100,\n",
       " ' A szállásunk egy Balaton melletti kis üdülőfaluban, Zamárdiban volt, a Postának az üdülőházában.\\n')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = 'SZTAKI-HLT/hubert-base-cc' # bert-base-multilingual-cased\n",
    "\n",
    "\n",
    "data_path = f\"D:/Data/neural-punctuator/\"\n",
    "os.makedirs(data_path + model_type, exist_ok=True)\n",
    "file_path = data_path + \"szeged.txt\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.readlines()\n",
    "    \n",
    "len(text), text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80875"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "text = list(OrderedDict.fromkeys(text))\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ez jutott az eszébe önkéntelenül.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "text = shuffle(text, random_state=0)\n",
    "\n",
    "text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('!', '.')\n",
    "    text = text.replace(':', ',')\n",
    "    text = text.replace('--', ',')\n",
    "    text = text.replace('-', ',')\n",
    "    text = text.replace(';', '.')\n",
    "    text = text.replace(' ,', ',')\n",
    "    text = text.replace('♫', '')\n",
    "\n",
    "    text = re.sub(r'--\\s?--', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    text = re.sub(r',\\s?,', ', ', text)\n",
    "    text = re.sub(r'\\.[\\s+.]+', '. ', text)\n",
    "    \n",
    "    text = re.sub(r',\\s?,', ',', text)\n",
    "    \n",
    "    remove_space_before = [',', '?', '.', '!', '\\n']\n",
    "    for c in remove_space_before:\n",
    "        text = text.replace(' ' + c, c)\n",
    "    \n",
    "    text = re.sub(r',\\s+[\\.\\s]+', ', ', text)\n",
    "    text = re.sub(r',\\s+[,\\s]+', ', ', text)\n",
    "    text = re.sub(r'\\.\\s+[,\\s]+', '. ', text)\n",
    "    text = text.lstrip('.,?')\n",
    "    \n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ez jutott az eszébe önkéntelenül.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [clean_text(t) for t in text]\n",
    "text = [t for t in text if len(t) > 0]\n",
    "text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nem lennék bunkó,., begyöpösödött agyú, naiv ember.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[29545]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29544 újabb párbeszéddoboz jelenik meg, amelyben az ok parancsgombra kell kattintani az állományok visszaállításához.\n"
     ]
    }
   ],
   "source": [
    "for i, t in enumerate(text):\n",
    "    if 'állományok visszaállításához' in t:\n",
    "        print(i, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4575, 8308, 3576, 3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\".?,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 4575, '?': 8308, ',': 3576}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token2id = {t: tokenizer.encode(t)[-2] for t in \".?,\"}\n",
    "target_token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4575, 8308, 3576]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ids = list(target_token2id.values())\n",
    "target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2target = {\n",
    "    0: 0,\n",
    "    -1: -1,\n",
    "}\n",
    "for i, ti in enumerate(target_ids):\n",
    "    id2target[ti] = i+1\n",
    "target2id = {value: key for key, value in id2target.items()}\n",
    "\n",
    "def create_target(text):\n",
    "    encoded_words, targets = [], []\n",
    "    \n",
    "    words = text.split(' ')\n",
    "\n",
    "    for word in tqdm(words):\n",
    "        target = 0\n",
    "        for target_token, target_id in target_token2id.items():\n",
    "            if word.endswith(target_token):\n",
    "                word = word.rstrip(target_token)\n",
    "                target = id2target[target_id]\n",
    "\n",
    "        encoded_word = tokenizer.encode(word, add_special_tokens=False)\n",
    "        \n",
    "        for w in encoded_word:\n",
    "            encoded_words.append(w)\n",
    "        for _ in range(len(encoded_word)-1):\n",
    "            targets.append(-1)\n",
    "        targets.append(target)\n",
    "#         print([tokenizer._convert_id_to_token(ew) for ew in encoded_word], target)\n",
    "        assert(len(encoded_word)>0)\n",
    "\n",
    "    return encoded_words, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1076033, 123448, 44033)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_n = 70_000\n",
    "valid_n = 8_000\n",
    "\n",
    "train_text = ' '.join(text[:train_n])\n",
    "valid_text = ' '.join(text[train_n:train_n+valid_n])\n",
    "test_text = ' '.join(text[train_n+valid_n:])\n",
    "\n",
    "len(train_text.split(' ')), len(valid_text.split(' ')), len(test_text.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2873"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text) - train_n - valid_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'történtek',\n",
       " 'a',\n",
       " 'ferencvárosban.',\n",
       " 'megfürödtünk',\n",
       " 'és',\n",
       " 'megszárítottuk',\n",
       " 'a',\n",
       " 'ruháinkat.',\n",
       " 'idén']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.split(' ')[455735-5:455735+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd3086c727246b8806c49903fed2015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1076033.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d26eead62d4f3cad3ea6bf3a426d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=123448.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11f9d2c52904772be22aaefdcef1269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=44033.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_tokens, train_targets = create_target(train_text)\n",
    "valid_tokens, valid_targets = create_target(valid_text)\n",
    "test_tokens, test_targets = create_target(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For backward campatibility\n",
    "train_tokens, train_targets = [train_tokens], [train_targets]\n",
    "valid_tokens, valid_targets = [valid_tokens], [valid_targets]\n",
    "test_tokens, test_targets = [test_tokens], [test_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_path + model_type, exist_ok=True)\n",
    "with open(data_path + f'{model_type}/train_data.pkl', 'wb') as f:\n",
    "    pickle.dump((train_tokens, train_targets), f)\n",
    "with open(data_path + f'{model_type}/valid_data.pkl', 'wb') as f:\n",
    "    pickle.dump((valid_tokens, valid_targets), f)\n",
    "with open(data_path + f'{model_type}/test_data.pkl', 'wb') as f:\n",
    "    pickle.dump((test_tokens, test_targets), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82375\t1849\t104632\t887177\t492591\n",
      "9355\t201\t11991\t101901\t56059\n",
      "3438\t76\t4232\t36287\t20047\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for ds in (train_targets, valid_targets, test_targets):\n",
    "    c = Counter((t for targets in ds for t in targets))\n",
    "    print('\\t'.join([str(c[i]) for i in (1,2,3,0,-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82375\t1849\t104632\t887177\t492591\n",
      "9355\t201\t11991\t101901\t56059\n",
      "3438\t76\t4232\t36287\t20047\n"
     ]
    }
   ],
   "source": [
    "for ds in (train_targets, valid_targets, test_targets):\n",
    "    c = Counter((t for targets in ds for t in targets))\n",
    "    print('\\t'.join([str(c[i]) for i in (1,2,3,0,-1)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
